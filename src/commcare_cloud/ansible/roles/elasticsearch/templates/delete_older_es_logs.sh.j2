#!/bin/bash
DAYS_TO_RETAIN_LOGS=$1

# Remove old logs
find {{ elasticsearch_data_dir }}/logs -mtime "+${DAYS_TO_RETAIN_LOGS}" -name "{{ elasticsearch_cluster_name }}.log.*" -delete

# Remove old slowlogs
find {{ elasticsearch_data_dir }}/logs -mtime "+${DAYS_TO_RETAIN_LOGS}" -name "{{ elasticsearch_cluster_name }}_index_search_slowlog.log.*" -delete
find {{ elasticsearch_data_dir }}/logs -mtime "+${DAYS_TO_RETAIN_LOGS}" -name "{{ elasticsearch_cluster_name }}_index_indexing_slowlog.log.*" -delete

# Compress slowlogs if file size is bigger than 2GB
LC_ALL=C find {{ elasticsearch_data_dir }}/logs ! -name *.gz -type f -size +"$((2000*1024*1024))c" -mmin +5 -exec sh -c 'f="{}"; mv -- "$f" "${f}_$(date +%Y%m%d_%H%M%S)"' \; 
LC_ALL=C find {{ elasticsearch_data_dir }}/logs ! -name *.gz -type f -size +"$((2000*1024*1024))c" -mmin +5 -exec gzip {} +
